{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/az-handwritten-alphabets-in-csv-format/A_Z Handwritten Data/A_Z Handwritten Data.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Model\nimport keras.layers as L\nfrom keras import backend as K\nfrom keras.utils import np_utils\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler","execution_count":2,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/az-handwritten-alphabets-in-csv-format/A_Z Handwritten Data/A_Z Handwritten Data.csv')","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.rename(columns = {'0': 'labels'}, inplace = True)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.drop('labels', axis = 1)\nY = data['labels']\nX.shape, Y.shape","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"((372450, 784), (372450,))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"(xTrain, xTest, yTrain, yTest) = train_test_split(X, Y)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler()\nscaler.fit(xTrain)","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"MinMaxScaler(copy=True, feature_range=(0, 1))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"xTrain = scaler.transform(xTrain)\nxTest = scaler.transform(xTest)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xTest.shape, xTrain.shape","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"((93113, 784), (279337, 784))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"xTrain = xTrain.reshape((xTrain.shape[0], 28, 28, 1)).astype('float32')\nxTest = xTest.reshape((xTest.shape[0], 28, 28, 1)).astype('float32')\nxTrain.shape, xTest.shape, yTrain.shape","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"((279337, 28, 28, 1), (93113, 28, 28, 1), (279337,))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"yTrain = np_utils.to_categorical(yTrain)\nyTest = np_utils.to_categorical(yTest)\nyTrain.shape, yTest.shape","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"((279337, 26), (93113, 26))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"numClasses = yTrain.shape[1]\nnumClasses","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"26"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# use keras.models.Model to save as .h5\nXinp = L.Input((28, 28, 1))\nX = L.Conv2D(64, (5, 5), activation = 'relu', data_format = 'channels_last', padding = 'same')(Xinp)\nX = L.Conv2D(64, (5, 5), activation = 'relu', data_format = 'channels_last', padding = 'same')(X)\nX = L.MaxPooling2D(pool_size = (2, 2))(X)\n\nX = L.Conv2D(128, (3, 3), activation = 'relu', data_format = 'channels_last', padding = 'same')(X)\nX = L.Conv2D(128, (3, 3), activation = 'relu', data_format = 'channels_last', padding = 'same')(X)\nX = L.MaxPooling2D(pool_size = (2, 2))(X)\n\nX = L.Dropout(0.2)(X)\n\nX = L.Flatten()(X)\nX = L.Dense(128, activation = 'relu')(X)\nX = L.Dense(128, activation = 'relu')(X)\nX = L.Dense(numClasses, activation = 'softmax')(X)\n\nmodel = Model(inputs=Xinp, outputs=X)","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":15,"outputs":[{"output_type":"stream","text":"Model: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 28, 28, 1)         0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 28, 28, 64)        1664      \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 28, 28, 64)        102464    \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 14, 14, 128)       73856     \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 14, 14, 128)       147584    \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 7, 7, 128)         0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 7, 7, 128)         0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 6272)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 128)               802944    \n_________________________________________________________________\ndense_2 (Dense)              (None, 128)               16512     \n_________________________________________________________________\ndense_3 (Dense)              (None, 26)                3354      \n=================================================================\nTotal params: 1,148,378\nTrainable params: 1,148,378\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(xTrain, yTrain, validation_data=(xTest, yTest), epochs=10, batch_size=256)","execution_count":16,"outputs":[{"output_type":"stream","text":"Train on 279337 samples, validate on 93113 samples\nEpoch 1/10\n279337/279337 [==============================] - 35s 127us/step - loss: 0.1735 - accuracy: 0.9519 - val_loss: 0.0566 - val_accuracy: 0.9844\nEpoch 2/10\n279337/279337 [==============================] - 31s 111us/step - loss: 0.0482 - accuracy: 0.9862 - val_loss: 0.0434 - val_accuracy: 0.9881\nEpoch 3/10\n279337/279337 [==============================] - 31s 111us/step - loss: 0.0363 - accuracy: 0.9894 - val_loss: 0.0419 - val_accuracy: 0.9883\nEpoch 4/10\n279337/279337 [==============================] - 32s 113us/step - loss: 0.0292 - accuracy: 0.9913 - val_loss: 0.0332 - val_accuracy: 0.9908\nEpoch 5/10\n279337/279337 [==============================] - 31s 111us/step - loss: 0.0243 - accuracy: 0.9924 - val_loss: 0.0308 - val_accuracy: 0.9920\nEpoch 6/10\n279337/279337 [==============================] - 31s 112us/step - loss: 0.0198 - accuracy: 0.9938 - val_loss: 0.0287 - val_accuracy: 0.9923\nEpoch 7/10\n279337/279337 [==============================] - 31s 111us/step - loss: 0.0172 - accuracy: 0.9946 - val_loss: 0.0267 - val_accuracy: 0.9936\nEpoch 8/10\n279337/279337 [==============================] - 31s 111us/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 0.0310 - val_accuracy: 0.9931\nEpoch 9/10\n279337/279337 [==============================] - 31s 111us/step - loss: 0.0136 - accuracy: 0.9955 - val_loss: 0.0331 - val_accuracy: 0.9923\nEpoch 10/10\n279337/279337 [==============================] - 31s 111us/step - loss: 0.0115 - accuracy: 0.9962 - val_loss: 0.0262 - val_accuracy: 0.9947\n","name":"stdout"},{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"<keras.callbacks.callbacks.History at 0x7f6abd3b61d0>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pickle import dump\nmodel.save('model.h5')\nwith open(\"scaler.pickle\", \"wb\") as fh:\n    dump(scaler, fh)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nchars = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\nimg = xTest[1].reshape((28, 28))\npred = chars[model.predict(img.reshape((1, 28, 28, 1)))[0].argmax()]\nplt.imshow(img)\nprint(pred)","execution_count":19,"outputs":[{"output_type":"stream","text":"O\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}